В процессе написания этого парсера, я решил ещё больше углубиться в тему асинхронности, многопоточности, многопроцессности. 

Сначала я хотел сделать абсолютно все функции асинхронными. Ну вот просто, чтобы всё летало, чтобы 5 миллиардов гитар скачивалось за 5 миллисекунд. Однако, я быстро понял, что так я запутаюсь, кроме того это не позволит мне разбивать мои функции.

Именно поэтому решено написать устройство моей команды здесь, чтобы не запутаться.



Итак, всё начинается с функции main(), которая на данный этап (я не знаю как будет в конце), последовательно! вызывает функции получения данных о гитарах с каждого магазина. Здесь нет места никакой асинхронности.

Следовательно, мы сначала получаем данные с комиссиончика, только после полной загрузки данных, получаем данные с последующего магазина и так далее. Конкретно здесь асинхронности быть не должно, так как скорее всего этот скрипт переедет в телеграмм-бота, который не всегда будет получать информацию обо всех магазинах сразу, а иногда только об одном.



Итак, что же происходит в самой функции получения информации с 1 магазина. Сначала мы синхронно получаем все ссылки на все гитары, так как это не занимает много времени.

А вот теперь подключается асинхронность. Мы создаём aiohttp.ClientSession(), чтобы использовать одну сессию для всех наших вызовов. Далее мы создаём список наших тасков для asyncio.gather. Здесь же записываем всю информацию в каждую таску - сессию, ссылку, а также название файла.

И запускаем asyncio.gather(*tasks).



Теперь опишу работы этой самой функции, которая является одной таской (кого бесит название таска, согласен с вами, просто так звучит круче, чем задача, типо программист весь такой).

В этой функции мы опять же асинхронно отправляем запрос, получая информацию с сайта - название гитары, её описание, ссылка на её картинку. Кроме того, здесь же мы скачиваем фото.

Это концепт функции для каждого из магазинов.